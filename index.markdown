---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---

## About Me

![image](/images/xinyu.jpg){: style="float: left; width: 30%; height: auto; margin-right: 20px; margin-bottom: 10px;"}


This is Xinyu! I am a Ph.D. student at the Department of Statistics and Data Science at the University of Pennsylvania, working with Dr. [Weijie Su](http://stat.wharton.upenn.edu/~suw/). In the meantime, I work with by Dr. [Tanwi Mallick](https://tanwimallick.github.io) at the Mathematics and Computer Science Division at the Argonne National Laboratory. 

My recent work focuses on probing and improving the safety aspects of deploying AI models. In general, I am interested in the theory and applications of machine learning and statistics. In my spare time, I also participate in hackathons and data science competitions. Here is my [CV](/assets/Yangxinyu_Xie_CV.pdf).

I finished my masterâ€™s degree in computer science at the University of Texas at Austin in 2021, advised by Dr. [Anna Gal](https://www.cs.utexas.edu/~panni/) and Dr. [Ngoc Tran](https://www.linkedin.com/in/ngoc-tran-43aa9879/). 

---

### Upcoming Presentations

I will be presenting posters at the following workshops at **NeurIPS 2024**:

- **WildfireGPT: Tailored Large Language Model for Wildfire Analysis**  
  *Tackling Climate Change with Machine Learning Workshop*  

- **A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners**  
  *Workshop on Statistical Frontiers in LLMs and Foundation Models* 

I will present at the **Joint Mathematics Meetings (JMM) 2025**:

- **Debiasing Watermarks for Large Language Models via Importance Sampling**  
  *AMS Special Session on Trustworthy AI Applications Including Machine Learning, PINN, and Inverse Problems*

- **Unveiling Large Language Model Vulnerabilities: A Geometric and Topological Approach to Adversarial Robustness**  
  *AMS Special Session on MRC Mathematics of Adversarial, Interpretable, and Explainable AI*  